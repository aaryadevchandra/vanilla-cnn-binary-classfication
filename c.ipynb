{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e444800-1803-48ba-b240-4e316c95209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b959e8-eda3-4a5d-ad82-822d69abcae8",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48571129-f11d-4692-955b-7cb88d36cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 3\n",
    "img_dimensions = (416, 416)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1448de51-96a1-410f-b262-67935f5d3040",
   "metadata": {},
   "source": [
    "### Reading and Reshaping Images for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a727bc-8fd3-4396-b9cf-946fc3cea3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "immature_img_paths = glob.glob('./train/immature/*')\n",
    "mature_img_paths = glob.glob('./train/mature/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e8f2053-2f40-4dc2-8a7c-11f062e8e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# immature_imgs_np = []\n",
    "# mature_imgs_np = []\n",
    "imgs_np = []\n",
    "for imm_img_path in immature_img_paths:\n",
    "    imgs_np.append(cv2.imread(imm_img_path))\n",
    "\n",
    "for m_img_path in mature_img_paths:\n",
    "    imgs_np.append(cv2.imread(m_img_path))\n",
    "\n",
    "imgs_np = np.array(imgs_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba343b3a-8d46-4f7a-af97-4f9d4c42ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# immature_imgs_np = immature_imgs_np.reshape(-1, num_channels, img_dimensions[0], img_dimensions[1])\n",
    "# mature_imgs_np = mature_imgs_np.reshape(-1, num_channels, img_dimensions[0], img_dimensions[1])\n",
    "imgs_np = imgs_np.reshape(-1, num_channels, img_dimensions[0], img_dimensions[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d78cc4f-2fec-4b83-b452-a509ca1c4526",
   "metadata": {},
   "source": [
    "### Classifier Network Defn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4310c1-6728-42c9-9403-c6f2e42346dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CataractClassifierNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.linear_net = nn.Sequential(\n",
    "                nn.Linear(in_features=5408, out_features=1024),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(in_features=1024, out_features=512),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(in_features=512, out_features=256),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(in_features=256, out_features=128),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(in_features=128, out_features=64),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(in_features=64, out_features=32),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(in_features=32, out_features=16),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(in_features=16, out_features=8),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(in_features=8, out_features=2),\n",
    "                nn.Softmax(dim=-1)\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.conv_net(x)\n",
    "        x = self.linear_net(x.reshape(batch_size, -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d14aa4-af8c-43a5-a2dd-658065b7d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccn = CataractClassifierNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "990cf94b-1e71-4362-b164-96b9f33c3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting image array to image tensor \n",
    "imgs_tensor = torch.from_numpy(imgs_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b7a3a-399e-4ead-be6f-06548ca43ff3",
   "metadata": {},
   "source": [
    "### Defining Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9feeb00-b742-4f43-8e7c-94583ffb5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ccn.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214d31b-5550-44f9-8bd0-338d737c7ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba2b10-df38-4da8-bdb4-dbd625ff1564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10de4de4-f52a-414b-9d83-3cbc162956a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(immature_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3074c65f-88f3-47e2-b1e0-34de42ff02f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mature_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2fd7143-d035-46d0-8707-58c7b5d730c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tensor = torch.zeros(len(immature_img_paths) + len(mature_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30cf9f26-5489-47f1-a9bf-62b2cd28b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tensor[:len(immature_img_paths)] = 0\n",
    "Y_tensor[len(immature_img_paths):] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17199697-cd7c-49e9-ba53-ffa52b41158c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1563824b-aa2d-4c39-a37d-a76dd8eaa078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b75c63c-6d82-49ae-b720-909e0b50189d",
   "metadata": {},
   "source": [
    "### Normalizing our Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "036ba6d5-cd77-454f-ac53-fa8e2861dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_tensor = imgs_tensor / torch.max(imgs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d10d4-f405-4e6c-825d-25380a0d5bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f67883-4598-4de6-ad35-db5637dbc6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8ae560e-5fd8-476d-8f01-f0c63fda22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(imgs_tensor, Y_tensor, test_size=0.1, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab788e93-04bc-4005-bd6f-305e1929ca96",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc6bc5dc-2f59-41c9-91bd-eb8479b14f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 tensor(0.6928, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 2 tensor(0.6927, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 3 tensor(0.6927, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 4 tensor(0.6926, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 5 tensor(0.6926, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 6 tensor(0.6925, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 7 tensor(0.6925, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 8 tensor(0.6924, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 9 tensor(0.6923, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 10 tensor(0.6922, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 11 tensor(0.6920, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 12 tensor(0.6918, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 13 tensor(0.6916, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 14 tensor(0.6912, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 15 tensor(0.6906, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 16 tensor(0.6898, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 17 tensor(0.6889, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 18 tensor(0.6877, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 19 tensor(0.6859, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 20 tensor(0.6834, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 21 tensor(0.6801, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 22 tensor(0.6760, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 23 tensor(0.6706, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 24 tensor(0.6636, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 25 tensor(0.6551, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 26 tensor(0.6453, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 27 tensor(0.6341, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 28 tensor(0.6225, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 29 tensor(0.6108, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 30 tensor(0.6027, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 31 tensor(0.6125, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 32 tensor(0.5892, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 33 tensor(0.6200, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 34 tensor(0.5809, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 35 tensor(0.5978, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 36 tensor(0.5938, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 37 tensor(0.5728, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 38 tensor(0.5864, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 39 tensor(0.5706, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 40 tensor(0.5671, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 41 tensor(0.5733, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 42 tensor(0.5624, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 43 tensor(0.5538, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 44 tensor(0.5603, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 45 tensor(0.5447, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 46 tensor(0.5484, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 47 tensor(0.5426, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 48 tensor(0.5334, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 49 tensor(0.5376, grad_fn=<NllLossBackward0>)\n",
      "EPOCH 50 tensor(0.5241, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for _ in range(epochs):\n",
    "    loss = loss_fn(ccn(X_train.float()), Y_train.long())\n",
    "    print(f\"EPOCH {_ + 1}\", loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdd89e58-efc6-462f-8160-e83407e7d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_softmax(y_true, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of the classification model with softmax outputs.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): True labels.\n",
    "    y_pred_proba (array-like): Predicted probabilities from the softmax function.\n",
    "\n",
    "    Returns:\n",
    "    float: Accuracy score as a float between 0 and 1.\n",
    "    \"\"\"\n",
    "    # Convert probabilities to predicted class labels\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    # Calculate accuracy\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    total_predictions = len(y_true)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad13bf-1ea7-42cf-9c8c-1900fc7f4faf",
   "metadata": {},
   "source": [
    "### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf2ecab1-1002-4bc3-a247-85e172f283ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804878048780488"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_softmax(Y_test.detach().numpy(), ccn(X_test.float()).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0872701-68a3-4353-9c6e-d6db261e787d",
   "metadata": {},
   "source": [
    "### Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c01abc1a-9291-4c3e-b586-9711d3c34953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8292682926829268"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_softmax(Y_train.detach().numpy(), ccn(X_train.float()).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2daaf60-6333-478d-9031-8943e287bfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
